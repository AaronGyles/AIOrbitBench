{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, scale\n",
    "\n",
    "# Function involved in pipeline\n",
    "def time_series(values1, time1, values2, time2, scaling=True, tscaling=True):\n",
    "    '''\n",
    "    Provides a scaled data frame of data from a simulation of a problem.\n",
    "\n",
    "    :param values1: Dictionary of orbital values for the first dataset\n",
    "    :param time1: An array of time for the first dataset\n",
    "    :param values2: Dictionary of orbital values for the second dataset\n",
    "    :param time2: An array of time for the second dataset\n",
    "    :param scaling: Boolean value of orbital value standardization scaling\n",
    "    :param tscaling: Boolean value of time array normalization scaling\n",
    "    :return: Tuple of two DataFrames (df1, df2) with scaled orbital values and time\n",
    "    '''\n",
    "\n",
    "    # First, create a dataframe of the values.\n",
    "    df1 = pd.DataFrame(values1)\n",
    "    df2 = pd.DataFrame(values2)\n",
    "    \n",
    "    # Add the time values to the Dataframe.\n",
    "    df1['Time'] = time1\n",
    "    df2['Time'] = time2\n",
    "    \n",
    "    # If scaling for data is True, then apply scaling\n",
    "    if scaling:\n",
    "        # Combine the DataFrames temporarily \n",
    "        # This ensures scaling is centered around the same mean for comparability.\n",
    "        data_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "        # Standardized values in the combined data.\n",
    "        for column in data_combined.columns:\n",
    "            # Do not Standardized time, we only want to normalize it later.\n",
    "            if column != 'Time':\n",
    "                # Apply Standardization (zero mean, unit variance)\n",
    "                data_combined[column] = scale(data_combined[column], axis=0)\n",
    "\n",
    "        # Split back to original DataFrames.\n",
    "        df1_scaled = data_combined.iloc[:len(df1)].copy()\n",
    "        df2_scaled = data_combined.iloc[len(df1):].copy()\n",
    "        \n",
    "        # Reset dataframe's index that got split due to the concatenation\n",
    "        df2_scaled = df2_scaled.reset_index(drop=True)\n",
    "\n",
    "        # Update the old data frames with the new scaled values\n",
    "        df1.update(df1_scaled)\n",
    "        df2.update(df2_scaled)\n",
    "\n",
    "\n",
    "    # If tscaling is set to True, normalize the time values in the dataframes.     \n",
    "    if tscaling:\n",
    "        # We need to fit the normalization to the dataframe with the highest time value.\n",
    "        if df1['Time'].max() >= df2['Time'].max():\n",
    "            # Fit the MinMaxScaler on the dataframe with the highest time value (df1).\n",
    "            scaler = MinMaxScaler()\n",
    "            df1['Time'] = scaler.fit_transform(df1[['Time']])\n",
    "            \n",
    "            # Transform the second time array (df2) using the same scaler.\n",
    "            df2['Time'] = scaler.transform(df2[['Time']])\n",
    "\n",
    "        else: \n",
    "            scaler = MinMaxScaler()\n",
    "            # Fit the MinMaxScaler on the dataframe with the highest time value (df2).\n",
    "            df2['Time'] = scaler.fit_transform(df2[['Time']])\n",
    "            \n",
    "            # Transform the first time array (df1) using the same scaler.\n",
    "            df1['Time'] = scaler.transform(df1[['Time']])\n",
    "\n",
    "    return df1, df2  # Return both DataFrames\n",
    "\n",
    "# Density of time points may change in a simulation - could be tricky to \n",
    "# make the time-series truly generic with adaptive timesteps in simulations.\n",
    "def interpolate_data(ref_df, ai_df):\n",
    "    '''\n",
    "    Interpolates the orbital element data in the DataFrame to match the \n",
    "    reference time array using forward filling.\n",
    "\n",
    "    :param ref_df: Dataframe with reference solution values.\n",
    "    :param ai_df: Dataframe with AI data values.\n",
    "    :return: A DataFrame with interpolated data.\n",
    "    '''\n",
    "\n",
    "    # Set index to the time column for interpolation.\n",
    "    ref_df.set_index('Time', inplace=True)\n",
    "    ai_df.set_index('Time', inplace=True)\n",
    "\n",
    "    # Make sure Ref data, AI data is sorted by Time.\n",
    "    ref_df = ref_df.sort_values(by='Time')\n",
    "    ai_df = ai_df.sort_values(by='Time')\n",
    "\n",
    "    if ai_df.shape[0] <= ref_df.shape[0]:\n",
    "\n",
    "        # Merge the two data frames with reference on the left and AI data on the right.\n",
    "        # Use forward filling to align data points.\n",
    "        merged_df = pd.merge_asof(ref_df, ai_df, on='Time', direction='forward')\n",
    "\n",
    "        # Interpolate the values except for time.\n",
    "        for col in ref_df.columns:\n",
    "            if col != 'Time':\n",
    "                # Interpolate the right side of the merged dataframe to the left side.\n",
    "                merged_df[col + '_y'] = merged_df[col + '_y'].interpolate()\n",
    "\n",
    "        # Split the merged dataframe to acquire the interpolated AI data\n",
    "        ai_df_interpolated = merged_df[[col + '_y' for col in ai_df.columns] + ['Time']].copy()\n",
    "        ai_df_interpolated.columns = list(ref_df.columns) + ['Time']\n",
    "\n",
    "        # Return data, making sure we reset the index of the reference data set\n",
    "        return ref_df.reset_index(), ai_df_interpolated\n",
    "\n",
    "    elif ai_df.shape[0] >= ref_df.shape[0]:\n",
    "\n",
    "        # Merge the two data frames with AI on the left and reference data on the right\n",
    "        # Use nearest neighbor interpolation for potential higher accuracy.\n",
    "        merged_df = pd.merge_asof(ai_df, ref_df, on='Time', suffixes=('_ai', '_ref'), direction='nearest')\n",
    "        \n",
    "        # Interpolate the orbital element columns using polynomial interpolation\n",
    "        for col in merged_df.columns:\n",
    "            if col != 'Time':\n",
    "                # Interpolate the right side of the merged dataframe to the left side\n",
    "                merged_df[col] = merged_df[col].interpolate(method='polynomial',order=5)\n",
    "\n",
    "        # Split the merged dataframe to acquire the interpolated reference data\n",
    "        ref_df_interpolated = pd.DataFrame()\n",
    "        for col in ref_df.reset_index().columns:\n",
    "           if col != 'Time':\n",
    "               ref_df_interpolated[col] = merged_df[col+'_ref']\n",
    "           else:\n",
    "               ref_df_interpolated[col] = merged_df[col]\n",
    "        # Return data, making sure we reset the index of the AI data set\n",
    "        return ref_df_interpolated, ai_df.reset_index()\n",
    "    \n",
    "\n",
    "def compute_score(ref_df, ai_df, tot_rmse=False):\n",
    "  '''\n",
    "  Calculates the Root Mean Squared Error (RMSE) between two DataFrames,\n",
    "  excluding the 'time' column.\n",
    "  \n",
    "  :param ref_df: Reference dataframe from solution of problem.\n",
    "  :param ai_df: Dataframe from AI's solution of problem.\n",
    "  :param tot_rmse: Boolean to calculate total RMSE across all columns\n",
    "  :return: a single floating-point number (total RMSE) or a Series of RMSE values for each column.\n",
    "  '''\n",
    "  \n",
    "  # Select only the columns with orbital data (exclude 'time')\n",
    "  data_columns = [col for col in ref_df.columns if col != 'Time']\n",
    "\n",
    "  # Calculate squared errors for the selected columns\n",
    "  squared_errors = (ref_df[data_columns] - ai_df[data_columns])**2  \n",
    "\n",
    "  # Calculate RMSE for each shared column\n",
    "  rmse_values = np.sqrt(squared_errors.mean())\n",
    "  \n",
    "  if tot_rmse:\n",
    "        # Calculate total RMSE by taking RMSE of individual RMSEs for each column\n",
    "        total_rmse = np.sqrt(rmse_values.mean())  \n",
    "        return total_rmse\n",
    "  \n",
    "  else:\n",
    "      # Return RMSE values as a Series \n",
    "      return rmse_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
